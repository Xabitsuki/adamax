{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Movie behind a Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.10:0.4.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.session.timeZone', 'UTC')\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of datasets\n",
    "\n",
    "The OpenSubtitles dataset is a compressed cluster of folders containing XML files. Each XML file is split into a script portion with the subtitles of the movie and a metadata portion with additional information about the movie or show. The name of one of the parent folders of the XML file is the corresponding IMDb identifier of the movie or show, thus allowing us to extract additional information from the IMDb dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have at our disposal the IMDb ratings and basics dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO scrape data https://datasets.imdbws.com/\n",
    "ratings_fn = \"title.ratings.tsv.gz\"\n",
    "basics_fn = \"title.basics.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1440|\n",
      "|tt0000002|          6.3|     172|\n",
      "|tt0000003|          6.6|    1041|\n",
      "|tt0000004|          6.4|     102|\n",
      "|tt0000005|          6.2|    1735|\n",
      "|tt0000006|          5.5|      91|\n",
      "|tt0000007|          5.5|     579|\n",
      "|tt0000008|          5.6|    1539|\n",
      "|tt0000009|          5.6|      74|\n",
      "|tt0000010|          6.9|    5127|\n",
      "|tt0000011|          5.4|     214|\n",
      "|tt0000012|          7.4|    8599|\n",
      "|tt0000013|          5.7|    1318|\n",
      "|tt0000014|          7.2|    3739|\n",
      "|tt0000015|          6.2|     660|\n",
      "|tt0000016|          5.9|     982|\n",
      "|tt0000017|          4.8|     197|\n",
      "|tt0000018|          5.5|     414|\n",
      "|tt0000019|          6.6|      13|\n",
      "|tt0000020|          5.1|     232|\n",
      "+---------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings = spark.read.option(\"header\", \"true\")\\\n",
    "                       .option(\"sep\", \"\\t\")\\\n",
    "                       .csv(\"imdb_data/\" + ratings_fn)\n",
    "df_ratings = df_ratings.selectExpr(\"tconst\", \n",
    "                                   \"cast(averageRating as float) averageRating\", \n",
    "                                   \"cast(numVotes as int) numVotes\")\n",
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|     \\N|           5.0|  [Animation, Short]|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      Pauvre Pierrot|      0|     1892|     \\N|           4.0|[Animation, Comed...|\n",
      "|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|     \\N|          null|  [Animation, Short]|\n",
      "|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|     \\N|           1.0|     [Comedy, Short]|\n",
      "|tt0000006|    short|   Chinese Opium Den|   Chinese Opium Den|      0|     1894|     \\N|           1.0|             [Short]|\n",
      "|tt0000007|    short|Corbett and Court...|Corbett and Court...|      0|     1894|     \\N|           1.0|      [Short, Sport]|\n",
      "|tt0000008|    short|Edison Kinetoscop...|Edison Kinetoscop...|      0|     1894|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000009|    movie|          Miss Jerry|          Miss Jerry|      0|     1894|     \\N|          45.0|           [Romance]|\n",
      "|tt0000010|    short|Employees Leaving...|La sortie de l'us...|      0|     1895|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000011|    short|Akrobatisches Pot...|Akrobatisches Pot...|      0|     1895|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000012|    short|The Arrival of a ...|L'arrivée d'un tr...|      0|     1896|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000013|    short|The Photographica...|Neuville-sur-Saôn...|      0|     1895|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000014|    short|Tables Turned on ...|   L'arroseur arrosé|      0|     1895|     \\N|           1.0|     [Comedy, Short]|\n",
      "|tt0000015|    short| Autour d'une cabine| Autour d'une cabine|      0|     1894|     \\N|           2.0|  [Animation, Short]|\n",
      "|tt0000016|    short|Barque sortant du...|Barque sortant du...|      0|     1895|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000017|    short|Italienischer Bau...|Italienischer Bau...|      0|     1895|     \\N|           1.0|[Documentary, Short]|\n",
      "|tt0000018|    short|Das boxende Känguruh|Das boxende Känguruh|      0|     1895|     \\N|           1.0|             [Short]|\n",
      "|tt0000019|    short|    The Clown Barber|    The Clown Barber|      0|     1898|     \\N|          null|     [Comedy, Short]|\n",
      "|tt0000020|    short|      The Derby 1895|      The Derby 1895|      0|     1895|     \\N|           1.0|[Documentary, Sho...|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to split genres\n",
    "udf_split = udf(lambda s: s.split(',') if s is not None else \"\", ArrayType(StringType()))\n",
    "\n",
    "df_basics = spark.read.option(\"header\", \"true\")\\\n",
    "                      .option(\"sep\", \"\\t\")\\\n",
    "                      .csv(\"imdb_data/\" + basics_fn)\n",
    "df_basics = df_basics.withColumn(\"rttmp\", df_basics.runtimeMinutes.cast(DoubleType()))\\\n",
    "                     .drop(\"runtimeMinutes\")\\\n",
    "                     .withColumnRenamed(\"rttmp\", \"runtimeMinutes\")\\\n",
    "                     .withColumn(\"gtmp\", udf_split(\"genres\"))\\\n",
    "                     .drop(\"genres\")\\\n",
    "                     .withColumnRenamed(\"gtmp\", \"genres\")\n",
    "df_basics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSubtitles dataset\n",
    "\n",
    "The dataset consists of 31 GB of XML files distributed in the following file structure: \n",
    "\n",
    "```\n",
    "├── opensubtitle\n",
    "│   ├── OpenSubtitles2018\n",
    "│   │   ├── Year\n",
    "│   │   │   ├── Id\n",
    "│   │   │   │   ├── #######.xml.gz\n",
    "│   │   │   │   ├── #######.xml.gz\n",
    "│   ├── en.tar.gz\n",
    "│   ├── fr.tar.gz\n",
    "│   ├── zh_cn.tar.gz\n",
    "```\n",
    "where\n",
    "- `######` is a 6-digit unique identifier of the file on the OpenSubtitles dataset.\n",
    "- `Year` is the year the movie or episode was made.\n",
    "- `Id` is a 5 to 7 digit identifier (if it's 7-digit it's also an IMDb identifier).\n",
    "\n",
    "The subtitles are provided in different languages. We only analyze the `OpenSubtitles2018` folder and it's the only folder we detail.\n",
    "\n",
    "The decompressed XML files vary in size, ranging from 5KB to 9000KB sized files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML Files\n",
    "\n",
    "Each XML file is split into a `document` and `metadata` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtitles\n",
    "\n",
    "The `document` section contains all the subtitles and its general structure is the following:\n",
    "\n",
    "```\n",
    "├── s\n",
    "│   ├── time: Integer\n",
    "│   ├── w: String\n",
    "```\n",
    "\n",
    "An example snippet of an XML file:\n",
    "\n",
    "```xml\n",
    "  <s id=\"1\">\n",
    "    <time id=\"T1S\" value=\"00:00:51,819\" />\n",
    "    <w id=\"1.1\">Travis</w>\n",
    "    <w id=\"1.2\">.</w>\n",
    "    <time id=\"T1E\" value=\"00:00:53,352\" />\n",
    "  </s>\n",
    "```\n",
    "\n",
    "The subtitles in each XML file are stored by **blocks** denoted by `s` with a unique `id` attribute (integers in increasing order starting at 1).  \n",
    "\n",
    "Each block (`<s id=\"1\">` for instance) has a:  \n",
    "\n",
    "1. Set of timestamps (denoted by `time`) with\n",
    " - A timestamp `id` attribute that can take two different formats: `T#S` or `T#E`, where _S_ indicates _start_, _E_ indicates _end_ and _#_ is an increasing integer. \n",
    " - A `value` attribute which has the format `HH:mm:ss,fff`.\n",
    "\n",
    "2. Set of words (denoted by `w`) with\n",
    " - an `id` attribute that is simply an increasing number of decimal numbers of the format `X.Y` where X is the string id and Y is the word id within the corresponding string\n",
    " - a non-empty `value` attribute that contains a token: a word or a punctuation character. \n",
    "\n",
    "It sometimes also has an `alternative`, `initial` and `emphasis` attribute.  \n",
    "\n",
    " - The `initial` attribute generally corresponds to slang words or mispronounced words because of an accent such as _lyin'_ instead of _lying_.  \n",
    " - The `alternative` attribute is another way of displaying the subtitle for example _HOW_ instead of _how_.\n",
    " - The `emphasis` attribute is a boolean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "The `metadata` section has the following structure:\n",
    "\n",
    "```\n",
    "├── Conversion\n",
    "│   ├── corrected_words: Integer\n",
    "│   ├── sentences: Integer\n",
    "│   ├── tokens: Integer\n",
    "│   ├── encoding: String (always utf-8)\n",
    "│   ├── unknown_words: Integer\n",
    "│   ├── ignored_blocks: Integer\n",
    "│   ├── truecased_words: Integer\n",
    "├── Subtitle\n",
    "│   ├── language: String\n",
    "│   ├── date: String\n",
    "│   ├── duration: String\n",
    "│   ├── cds: String (presented as #/# where # is an int)\n",
    "│   ├── blocks: Integer\n",
    "│   ├── confidence: Double\n",
    "├── Source\n",
    "│   ├── genre: String[] (up to 3 genres)\n",
    "│   ├── year: Integer\n",
    "│   ├── duration: Integer (in minutes)\n",
    "│   ├── original: String\n",
    "│   ├── country: String\n",
    "```\n",
    "\n",
    "We note that some XML files may not have all the entries. \n",
    "We can use the metadata to obtain additional information about the movie or show's subtitles and compute certain statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "Going through the dataset we notice a few things:\n",
    "\n",
    "1. The dataset has meaningless folders. For example, the folder 1858/ is empty.\n",
    "2. Dataset contains XML files that are not related to movies or TV shows. For example, the folder 666/ contains Justin Bieber song subtitles.  \n",
    "3. Trailer of films can be present in the dataset. For example, the folder 2018/ we found for example Black Panther teaser trailer subtitles.\n",
    "4. Each movie might have more than 1 subtitle file.\n",
    "5. Some subtitle files contain text that is not related to the movie, like credits to the person who made the subtitles.\n",
    "6. The IDMDb folder name is not always a 7-digit number, meaning it is not always a valid IMDb identifer and we can't retrieve the IMDb info.\n",
    "7. Each block may have an arbitrary number (including 0) of timestamps associated to it.\n",
    "\n",
    "To solve points 1 and 2, we ignore all the folders which aren't inside the range of 1920-2018.\n",
    "\n",
    "To solve point 3, we drop trailers by looking at the `duration` field in the metadata section.\n",
    "\n",
    "To solve point 4, we simply take the first one.\n",
    "\n",
    "To solve point 6, we keep movies that have a correct IMDb identifier. Hence, all the files in folders that don't have a 7-digit folder name are dropped.\n",
    "\n",
    "To solve point 7, we decide not to associate a timestamp to each word for the moment.\n",
    " \n",
    "For the moment, we take a sample of the dataset from the cluster (see python script `extract_sample_2.py`) by collecting 1 or 2 movies for each year in the range 1920-2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing an analysis of the files and considering the statistics we want to obtain taking the size of our data into account, we decide to load the metadata and subtitles directly into 1 dataframe where we manipulate it as before. We decide not to extract all tokens at first as it would induce into very heavy computations. We store the text in an array of subtitles where each subtitle is an array of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: long (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- conversion: struct (nullable = true)\n",
      " |    |    |-- corrected_words: long (nullable = true)\n",
      " |    |    |-- encoding: string (nullable = true)\n",
      " |    |    |-- ignored_blocks: long (nullable = true)\n",
      " |    |    |-- sentences: long (nullable = true)\n",
      " |    |    |-- tokens: long (nullable = true)\n",
      " |    |    |-- truecased_words: long (nullable = true)\n",
      " |    |    |-- unknown_words: long (nullable = true)\n",
      " |    |-- source: struct (nullable = true)\n",
      " |    |    |-- duration: long (nullable = true)\n",
      " |    |    |-- genre: string (nullable = true)\n",
      " |    |    |-- year: long (nullable = true)\n",
      " |    |-- subtitle: struct (nullable = true)\n",
      " |    |    |-- blocks: long (nullable = true)\n",
      " |    |    |-- cds: string (nullable = true)\n",
      " |    |    |-- confidence: double (nullable = true)\n",
      " |    |    |-- date: string (nullable = true)\n",
      " |    |    |-- duration: string (nullable = true)\n",
      " |    |    |-- language: string (nullable = true)\n",
      " |-- s: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _emphasis: boolean (nullable = true)\n",
      " |    |    |-- _id: long (nullable = true)\n",
      " |    |    |-- time: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |    |    |-- _id: string (nullable = true)\n",
      " |    |    |    |    |-- _value: string (nullable = true)\n",
      " |    |    |-- w: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |    |    |-- _alternative: string (nullable = true)\n",
      " |    |    |    |    |-- _emphasis: boolean (nullable = true)\n",
      " |    |    |    |    |-- _id: double (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|    _id|                meta|                   s|\n",
      "+-------+--------------------+--------------------+\n",
      "|6887453|[[0, utf-8, 2, 96...|[[, 1, [[, T1S, 0...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imdb_id = '6464116'\n",
    "df_document_example = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "                                     .options(rowTag='document') \\\n",
    "                                     .load('sample_dataset/2017/6464116/6887453.xml.gz')\n",
    "df_document_example.printSchema()\n",
    "df_document_example.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid confusion, we will set some naming conventions. We will refer to certain attributes as follows:\n",
    "\n",
    "- The `s` array as **blocks**\n",
    "- An element of blocks, as a **block**.\n",
    "- The `w` array as **elements**\n",
    "- An element of elements, as **element**.\n",
    "- `_VALUE` as a **token**\n",
    "- A **subtitle** is a list of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that retrieves the tokens from the elements (`w` array) and returns an array of subtitles, where each subtitle is a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_subtitles_array(sentences):\n",
    "    \"\"\"Function to map the elements (a struct containing tokens)\n",
    "    to a list of list of tokens \"\"\"\n",
    "    s_list = []\n",
    "    if sentences is None:\n",
    "        return s_list\n",
    "    for words in sentences:\n",
    "        w_list = []\n",
    "        if words and \"w\" in words and words[\"w\"]:\n",
    "            for w in words[\"w\"]:\n",
    "                if '_VALUE' in w and w['_VALUE']:\n",
    "                    w_list.append(w['_VALUE'])\n",
    "                \n",
    "            s_list.append(w_list)\n",
    "\n",
    "    return s_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a couple of udf functions we will later use for the manipulation of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to spark function\n",
    "udf_subtitles_array = udf(to_subtitles_array, ArrayType(ArrayType(StringType())))\n",
    "# Convert array of words into a single string\n",
    "udf_sentence = udf(lambda x: ' '.join(x), StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if correct schema\n",
    "def has_correct_schema(df):\n",
    "    arguments = [\n",
    "                 \"meta.conversion.sentences\",\n",
    "                 \"meta.source.year\", \n",
    "                 \"meta.subtitle.blocks\",\n",
    "                 \"meta.subtitle.duration\",\n",
    "                 \"meta.subtitle.language\",\n",
    "                 \"s\"]\n",
    "    for col in arguments:\n",
    "        try:\n",
    "            df[col]\n",
    "        except AnalysisException:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "schema_films = StructType([StructField('tconst', StringType(), False),\n",
    "                               StructField('num_subtitles', LongType(), True),\n",
    "                               StructField('year', LongType(), True),\n",
    "                               StructField('blocks', LongType(), True),\n",
    "                               StructField('subtitle_mins', DoubleType(), True),\n",
    "                               StructField('subtitles', ArrayType(ArrayType(StringType())), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below structures our data to the format we want to then process all the queries we need: We link the movie with the proper imdbID, we get all the subtitles, change the subtitle duration to be in seconds (We assume for this that they all have the same format and after exploring the dataset we know the vast majority does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_correct_schema(df_document_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df_document, imdb_id):\n",
    "    \"\"\"Restructures and selects the columns of a dataframe of an XML\n",
    "    file with its corresponding IMDB Id\"\"\"\n",
    "    # Create IMDb ID and subtitles column\n",
    "    df_film_sentences = df_document.withColumn(\"tconst\", lit(\"tt\" + imdb_id))\\\n",
    "                                   .withColumn(\"subtitles\", udf_subtitles_array(\"s\"))\n",
    "    \n",
    "    # Select metadata and previously created columns\n",
    "    df_result = df_film_sentences.selectExpr(\"tconst\",\n",
    "                                             \"meta.conversion.sentences as num_subtitles\",\n",
    "                                             \"meta.source.year\", \n",
    "                                             \"meta.subtitle.blocks\",\n",
    "                                             \"meta.subtitle.duration as subtitle_duration\",\n",
    "                                             \"meta.subtitle.language\",\n",
    "                                             \"subtitles\")\n",
    "    # Split genre column and convert subtitle duration to seconds\n",
    "    df_result = df_result.withColumn(\"subtitle_mins\", \n",
    "                                     unix_timestamp(df_result.subtitle_duration, \"HH:mm:ss,SSS\") / 60)\n",
    "    # Discard redundant columns\n",
    "    return df_result.select(\"tconst\", \"num_subtitles\", \"year\", \"blocks\", \"subtitle_mins\", \"subtitles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying it on the example XML file, we see how our corresponding schema is much more simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = false)\n",
      " |-- num_subtitles: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- blocks: long (nullable = true)\n",
      " |-- subtitle_mins: double (nullable = true)\n",
      " |-- subtitles: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n",
      "+---------+-------------+----+------+-------------+--------------------+\n",
      "|   tconst|num_subtitles|year|blocks|subtitle_mins|           subtitles|\n",
      "+---------+-------------+----+------+-------------+--------------------+\n",
      "|tt6464116|          967|2017|   888|         40.7|[[[, shots, firin...|\n",
      "+---------+-------------+----+------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_document_example = clean_df(df_document_example, imdb_id)\n",
    "df_document_example.printSchema()\n",
    "df_document_example.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generalize what we have done so far. We would like to create a dataframe for several XML files, so we define a function that does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    \"\"\"Load an XML subtitles file into a dataframe\"\"\"\n",
    "    df_film = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "                             .options(rowTag='document')\\\n",
    "                             .load(path)\n",
    "    return df_film"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a dataframe for all the XML files in the sample dataset. We will later expand it to cover a bigger quantity of films. We call it `df_films` because it contains all the information for each film/show in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#path = \"sample_dataset/\"\n",
    "# Create empty dataframe with same schema\n",
    "\n",
    "\n",
    "#df_films = spark.createDataFrame([], schema_films)\n",
    "#film_list = []\n",
    "#for year in os.listdir(path):\n",
    " #   if not year.startswith('.'):\n",
    "  #      for imdb_id in os.listdir(path + year):\n",
    "   #         if not imdb_id.startswith('.'):\n",
    "    #            current_path = path + year + \"/\" + imdb_id\n",
    "     #           for idx, file in enumerate(os.listdir(current_path)):\n",
    "      #                  # Create a dataframe for each file\n",
    "       #                 df_document = load_df(current_path + '/' + file)\n",
    "        #                if has_correct_schema(df_document):\n",
    "                            # Restructure dataframe and add it to df_films\n",
    "         #                   film_list.append(clean_df(df_document, imdb_id))\n",
    "                        \n",
    "\n",
    "#             df_m.show()\n",
    "#             print(current_path + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(*dfs):\n",
    "    first, rest = dfs[0], dfs[1:]  # Python 3.x, for 2.x you'll have to unpack manually\n",
    "    return first.sql_ctx.createDataFrame(\n",
    "        first.sql_ctx._sc.union([df.rdd for df in dfs]),\n",
    "        first.schema\n",
    "    )\n",
    "#df_films = unionAll(*film_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the same structure to create dataframes in the cluster which contains all the films we wanted to focus on. Which are the ones with more than 5000 reviews and movies specifically (the script can be found under the name `cluster/parquet2.py`. To filter the appropiate files we used the imdb datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [spark.read.parquet(\"parquets/\" +path) for path in os.listdir(\"parquets\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total films we will be focusing on then is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4275"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_films = unionAll(*df_list)\n",
    "df_films.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "Here we discuss how we want to proceed with our data.\n",
    "\n",
    "We consider only films with more that 10000 reviews as IMDb considers this a good metric to estimate the public actual approval of a film.\n",
    "\n",
    "We first start by analyzing the 1000 best films according to IMDB with more that 20000 reviews. We look into the resulting dataframe columns and  try to look for some kind of pattern. We look at the ratio of subtitle time per runtime, the most used words in the films, the ratio of distinct words per total number of words, average sentence length, number of sentences. We draw conclusions if we see any apparent relation. Afterwards if we can find a relation between rating and one of the resulting values, we do the same tests on the worst imdb films with more than 20000 reviews. If we find that a relation holds for both groups we make a statement assuming there exists a relationship\n",
    "\n",
    "We know this is very vague and we cannot make a strong statement based on what weve found, if we have found anything because we haven't taken into consideration many variables such as the movie genre, the year of release, if it is an adult film or not. Also the country of origin would be a variable to take into account but we dont have it yet. We can also check the box office for the best films if we consider.\n",
    "\n",
    "To proceed then, we ask what are the most popular genres and we look into how the statistics for the 10 most popular ones behave. Can we find any relationship between a genre and the statistics. We look aswell for relationships between genre and rating. Is the genre of a movie a variable which influences average rating. \n",
    "\n",
    "It is all interconnected, we ask ourselves for example, given an action movie, are the value of the statistics influential to its average rating. \n",
    "\n",
    "We havent taken TIME into account either! We look into different time periods, particular years where something occured (WW2 end or smth like that) and we try using the same statistics, to find relationships. We need to choose how to address the other variables such as genre and if it is an adult film or not.\n",
    "\n",
    "After analyzing this data if we find that there are actually dependencies between the values, we decide to create a small learning algorithm to predict the rating of a film given its script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_ratings.filter(df_ratings.numVotes > 20000)\n",
    "df_50_best = df_films.join(df_filtered, [\"tconst\"])\\\n",
    "                     .orderBy(df_ratings.averageRating.desc())\\\n",
    "                     .select(\"num_subtitles\", \n",
    "                             \"averageRating\", \n",
    "                             \"numVotes\", \"year\", \"tconst\")\\\n",
    "                     .take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cest de la merde pour linstant vue la taille du dataset\n",
    "df_pd_example = pd.DataFrame(df_50_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1570</td>\n",
       "      <td>9.4</td>\n",
       "      <td>98731</td>\n",
       "      <td>2016</td>\n",
       "      <td>tt5813916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1617</td>\n",
       "      <td>9.4</td>\n",
       "      <td>32554</td>\n",
       "      <td>1975</td>\n",
       "      <td>tt0252487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2050</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1986545</td>\n",
       "      <td>2008</td>\n",
       "      <td>tt0468569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2917</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1042076</td>\n",
       "      <td>1993</td>\n",
       "      <td>tt0108052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2071</td>\n",
       "      <td>8.9</td>\n",
       "      <td>598247</td>\n",
       "      <td>1966</td>\n",
       "      <td>tt0060196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1570</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1766484</td>\n",
       "      <td>2010</td>\n",
       "      <td>tt1375666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2603</td>\n",
       "      <td>8.8</td>\n",
       "      <td>21918</td>\n",
       "      <td>2013</td>\n",
       "      <td>tt3417422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2976</td>\n",
       "      <td>8.7</td>\n",
       "      <td>869871</td>\n",
       "      <td>1990</td>\n",
       "      <td>tt0099685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1952</td>\n",
       "      <td>8.7</td>\n",
       "      <td>801712</td>\n",
       "      <td>1975</td>\n",
       "      <td>tt0073486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1570</td>\n",
       "      <td>8.6</td>\n",
       "      <td>28147</td>\n",
       "      <td>2008</td>\n",
       "      <td>tt1152758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1399</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1083316</td>\n",
       "      <td>1991</td>\n",
       "      <td>tt0102926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1695</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1083609</td>\n",
       "      <td>1977</td>\n",
       "      <td>tt0076759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3134</td>\n",
       "      <td>8.6</td>\n",
       "      <td>339060</td>\n",
       "      <td>1946</td>\n",
       "      <td>tt0038650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>141</td>\n",
       "      <td>8.5</td>\n",
       "      <td>28554</td>\n",
       "      <td>2011</td>\n",
       "      <td>tt0770802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1448</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1166708</td>\n",
       "      <td>2000</td>\n",
       "      <td>tt0172495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1795</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1025762</td>\n",
       "      <td>2006</td>\n",
       "      <td>tt0482571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>964</td>\n",
       "      <td>8.5</td>\n",
       "      <td>192040</td>\n",
       "      <td>1988</td>\n",
       "      <td>tt0095765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36</td>\n",
       "      <td>8.5</td>\n",
       "      <td>181239</td>\n",
       "      <td>1936</td>\n",
       "      <td>tt0027977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1482</td>\n",
       "      <td>8.5</td>\n",
       "      <td>172669</td>\n",
       "      <td>1940</td>\n",
       "      <td>tt0032553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1796</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1000094</td>\n",
       "      <td>2000</td>\n",
       "      <td>tt0209144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1041</td>\n",
       "      <td>8.5</td>\n",
       "      <td>261367</td>\n",
       "      <td>1968</td>\n",
       "      <td>tt0064116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1133</td>\n",
       "      <td>8.5</td>\n",
       "      <td>875210</td>\n",
       "      <td>1991</td>\n",
       "      <td>tt0103064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2428</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1037421</td>\n",
       "      <td>2006</td>\n",
       "      <td>tt0407887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>742</td>\n",
       "      <td>8.5</td>\n",
       "      <td>185327</td>\n",
       "      <td>1988</td>\n",
       "      <td>tt0095327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2285</td>\n",
       "      <td>8.5</td>\n",
       "      <td>108850</td>\n",
       "      <td>2016</td>\n",
       "      <td>tt5074352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>687</td>\n",
       "      <td>8.4</td>\n",
       "      <td>872076</td>\n",
       "      <td>2008</td>\n",
       "      <td>tt0910970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1176</td>\n",
       "      <td>8.4</td>\n",
       "      <td>402545</td>\n",
       "      <td>1964</td>\n",
       "      <td>tt0057012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1401</td>\n",
       "      <td>8.4</td>\n",
       "      <td>113644</td>\n",
       "      <td>2016</td>\n",
       "      <td>tt5311514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1336</td>\n",
       "      <td>8.4</td>\n",
       "      <td>311172</td>\n",
       "      <td>2006</td>\n",
       "      <td>tt0405094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>456</td>\n",
       "      <td>8.3</td>\n",
       "      <td>137542</td>\n",
       "      <td>1927</td>\n",
       "      <td>tt0017136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1553</td>\n",
       "      <td>8.3</td>\n",
       "      <td>98002</td>\n",
       "      <td>1948</td>\n",
       "      <td>tt0040897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2168</td>\n",
       "      <td>8.3</td>\n",
       "      <td>233199</td>\n",
       "      <td>1962</td>\n",
       "      <td>tt0056172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>798</td>\n",
       "      <td>8.3</td>\n",
       "      <td>23771</td>\n",
       "      <td>1948</td>\n",
       "      <td>tt0040725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1505</td>\n",
       "      <td>8.3</td>\n",
       "      <td>52684</td>\n",
       "      <td>1996</td>\n",
       "      <td>tt0116231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1202</td>\n",
       "      <td>8.3</td>\n",
       "      <td>21586</td>\n",
       "      <td>1988</td>\n",
       "      <td>tt0097223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1984</td>\n",
       "      <td>8.3</td>\n",
       "      <td>262282</td>\n",
       "      <td>1959</td>\n",
       "      <td>tt0053125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1620</td>\n",
       "      <td>8.3</td>\n",
       "      <td>188347</td>\n",
       "      <td>1952</td>\n",
       "      <td>tt0045152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>882</td>\n",
       "      <td>8.3</td>\n",
       "      <td>120708</td>\n",
       "      <td>1948</td>\n",
       "      <td>tt0040522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>868</td>\n",
       "      <td>8.3</td>\n",
       "      <td>55908</td>\n",
       "      <td>1952</td>\n",
       "      <td>tt0044741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1568</td>\n",
       "      <td>8.3</td>\n",
       "      <td>262705</td>\n",
       "      <td>1962</td>\n",
       "      <td>tt0056592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>991</td>\n",
       "      <td>8.3</td>\n",
       "      <td>21861</td>\n",
       "      <td>2016</td>\n",
       "      <td>tt5929776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>866</td>\n",
       "      <td>8.3</td>\n",
       "      <td>20574</td>\n",
       "      <td>1975</td>\n",
       "      <td>tt0071411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2026</td>\n",
       "      <td>8.3</td>\n",
       "      <td>121979</td>\n",
       "      <td>1944</td>\n",
       "      <td>tt0036775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1460</td>\n",
       "      <td>8.3</td>\n",
       "      <td>307632</td>\n",
       "      <td>1958</td>\n",
       "      <td>tt0052357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>650</td>\n",
       "      <td>8.3</td>\n",
       "      <td>521288</td>\n",
       "      <td>1968</td>\n",
       "      <td>tt0062622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2676</td>\n",
       "      <td>8.3</td>\n",
       "      <td>611284</td>\n",
       "      <td>1989</td>\n",
       "      <td>tt0097576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1206</td>\n",
       "      <td>8.3</td>\n",
       "      <td>678227</td>\n",
       "      <td>2000</td>\n",
       "      <td>tt0180093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1366</td>\n",
       "      <td>8.3</td>\n",
       "      <td>445971</td>\n",
       "      <td>1975</td>\n",
       "      <td>tt0071853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>749</td>\n",
       "      <td>8.3</td>\n",
       "      <td>92817</td>\n",
       "      <td>1961</td>\n",
       "      <td>tt0055630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>744</td>\n",
       "      <td>8.3</td>\n",
       "      <td>196508</td>\n",
       "      <td>1965</td>\n",
       "      <td>tt0059578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1        2     3          4\n",
       "0   1570  9.4    98731  2016  tt5813916\n",
       "1   1617  9.4    32554  1975  tt0252487\n",
       "2   2050  9.0  1986545  2008  tt0468569\n",
       "3   2917  8.9  1042076  1993  tt0108052\n",
       "4   2071  8.9   598247  1966  tt0060196\n",
       "5   1570  8.8  1766484  2010  tt1375666\n",
       "6   2603  8.8    21918  2013  tt3417422\n",
       "7   2976  8.7   869871  1990  tt0099685\n",
       "8   1952  8.7   801712  1975  tt0073486\n",
       "9   1570  8.6    28147  2008  tt1152758\n",
       "10  1399  8.6  1083316  1991  tt0102926\n",
       "11  1695  8.6  1083609  1977  tt0076759\n",
       "12  3134  8.6   339060  1946  tt0038650\n",
       "13   141  8.5    28554  2011  tt0770802\n",
       "14  1448  8.5  1166708  2000  tt0172495\n",
       "15  1795  8.5  1025762  2006  tt0482571\n",
       "16   964  8.5   192040  1988  tt0095765\n",
       "17    36  8.5   181239  1936  tt0027977\n",
       "18  1482  8.5   172669  1940  tt0032553\n",
       "19  1796  8.5  1000094  2000  tt0209144\n",
       "20  1041  8.5   261367  1968  tt0064116\n",
       "21  1133  8.5   875210  1991  tt0103064\n",
       "22  2428  8.5  1037421  2006  tt0407887\n",
       "23   742  8.5   185327  1988  tt0095327\n",
       "24  2285  8.5   108850  2016  tt5074352\n",
       "25   687  8.4   872076  2008  tt0910970\n",
       "26  1176  8.4   402545  1964  tt0057012\n",
       "27  1401  8.4   113644  2016  tt5311514\n",
       "28  1336  8.4   311172  2006  tt0405094\n",
       "29   456  8.3   137542  1927  tt0017136\n",
       "30  1553  8.3    98002  1948  tt0040897\n",
       "31  2168  8.3   233199  1962  tt0056172\n",
       "32   798  8.3    23771  1948  tt0040725\n",
       "33  1505  8.3    52684  1996  tt0116231\n",
       "34  1202  8.3    21586  1988  tt0097223\n",
       "35  1984  8.3   262282  1959  tt0053125\n",
       "36  1620  8.3   188347  1952  tt0045152\n",
       "37   882  8.3   120708  1948  tt0040522\n",
       "38   868  8.3    55908  1952  tt0044741\n",
       "39  1568  8.3   262705  1962  tt0056592\n",
       "40   991  8.3    21861  2016  tt5929776\n",
       "41   866  8.3    20574  1975  tt0071411\n",
       "42  2026  8.3   121979  1944  tt0036775\n",
       "43  1460  8.3   307632  1958  tt0052357\n",
       "44   650  8.3   521288  1968  tt0062622\n",
       "45  2676  8.3   611284  1989  tt0097576\n",
       "46  1206  8.3   678227  2000  tt0180093\n",
       "47  1366  8.3   445971  1975  tt0071853\n",
       "48   749  8.3    92817  1961  tt0055630\n",
       "49   744  8.3   196508  1965  tt0059578"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
