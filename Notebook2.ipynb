{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Movie behind a Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.10:0.4.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.session.timeZone', 'UTC')\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of datasets\n",
    "\n",
    "The OpenSubtitles dataset is a compressed cluster of folders containing XML files. Each XML file is split into a script portion with the subtitles of the movie and a metadata portion with additional information about the movie or show. The name of one of the parent folders of the XML file is the corresponding IMDb identifier of the movie or show, thus allowing us to extract additional information from the IMDb dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have at our disposal the IMDb ratings and basics dataset. For the moment we have downloaded the files locally, but we would like to scrape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO scrape data https://datasets.imdbws.com/\n",
    "ratings_fn = \"title.ratings.tsv.gz\"\n",
    "basics_fn = \"title.basics.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1440|\n",
      "|tt0000002|          6.3|     172|\n",
      "|tt0000003|          6.6|    1041|\n",
      "|tt0000004|          6.4|     102|\n",
      "|tt0000005|          6.2|    1735|\n",
      "|tt0000006|          5.5|      91|\n",
      "|tt0000007|          5.5|     579|\n",
      "|tt0000008|          5.6|    1539|\n",
      "|tt0000009|          5.6|      74|\n",
      "|tt0000010|          6.9|    5127|\n",
      "|tt0000011|          5.4|     214|\n",
      "|tt0000012|          7.4|    8599|\n",
      "|tt0000013|          5.7|    1318|\n",
      "|tt0000014|          7.2|    3739|\n",
      "|tt0000015|          6.2|     660|\n",
      "|tt0000016|          5.9|     982|\n",
      "|tt0000017|          4.8|     197|\n",
      "|tt0000018|          5.5|     414|\n",
      "|tt0000019|          6.6|      13|\n",
      "|tt0000020|          5.1|     232|\n",
      "+---------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings = spark.read.option(\"header\", \"true\")\\\n",
    "                       .option(\"sep\", \"\\t\")\\\n",
    "                       .csv(\"imdb_data/\" + ratings_fn)\n",
    "df_ratings = df_ratings.selectExpr(\"tconst\", \"cast(averageRating as float) averageRating\", \"cast(numVotes as int) numVotes\")\n",
    "df_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------------+--------------+\n",
      "|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|              genres|runtimeMinutes|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------------+--------------+\n",
      "|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|     \\N|     Animation,Short|           5.0|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      Pauvre Pierrot|      0|     1892|     \\N|Animation,Comedy,...|           4.0|\n",
      "|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|     \\N|     Animation,Short|          null|\n",
      "|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|     \\N|        Comedy,Short|           1.0|\n",
      "|tt0000006|    short|   Chinese Opium Den|   Chinese Opium Den|      0|     1894|     \\N|               Short|           1.0|\n",
      "|tt0000007|    short|Corbett and Court...|Corbett and Court...|      0|     1894|     \\N|         Short,Sport|           1.0|\n",
      "|tt0000008|    short|Edison Kinetoscop...|Edison Kinetoscop...|      0|     1894|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000009|    movie|          Miss Jerry|          Miss Jerry|      0|     1894|     \\N|             Romance|          45.0|\n",
      "|tt0000010|    short|Employees Leaving...|La sortie de l'us...|      0|     1895|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000011|    short|Akrobatisches Pot...|Akrobatisches Pot...|      0|     1895|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000012|    short|The Arrival of a ...|L'arrivée d'un tr...|      0|     1896|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000013|    short|The Photographica...|Neuville-sur-Saôn...|      0|     1895|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000014|    short|Tables Turned on ...|   L'arroseur arrosé|      0|     1895|     \\N|        Comedy,Short|           1.0|\n",
      "|tt0000015|    short| Autour d'une cabine| Autour d'une cabine|      0|     1894|     \\N|     Animation,Short|           2.0|\n",
      "|tt0000016|    short|Barque sortant du...|Barque sortant du...|      0|     1895|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000017|    short|Italienischer Bau...|Italienischer Bau...|      0|     1895|     \\N|   Documentary,Short|           1.0|\n",
      "|tt0000018|    short|Das boxende Känguruh|Das boxende Känguruh|      0|     1895|     \\N|               Short|           1.0|\n",
      "|tt0000019|    short|    The Clown Barber|    The Clown Barber|      0|     1898|     \\N|        Comedy,Short|          null|\n",
      "|tt0000020|    short|      The Derby 1895|      The Derby 1895|      0|     1895|     \\N|Documentary,Short...|           1.0|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_basics = spark.read.option(\"header\", \"true\")\\\n",
    "                      .option(\"sep\", \"\\t\")\\\n",
    "                      .csv(\"imdb_data/\" + basics_fn)\n",
    "df_basics = df_basics.withColumn(\"rttmp\", df_basics.runtimeMinutes.cast(DoubleType())) \\\n",
    "                     .drop(\"runtimeMinutes\").withColumnRenamed(\"rttmp\", \"runtimeMinutes\")\n",
    "df_basics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSubtitles dataset\n",
    "\n",
    "The dataset consists of 31 GB of XML files distributed in the following file structure: \n",
    "\n",
    "```\n",
    "├── opensubtitle\n",
    "│   ├── OpenSubtitles2018\n",
    "│   │   ├── Year\n",
    "│   │   │   ├── Id\n",
    "│   │   │   │   ├── #######.xml.gz\n",
    "│   │   │   │   ├── #######.xml.gz\n",
    "│   ├── en.tar.gz\n",
    "│   ├── fr.tar.gz\n",
    "│   ├── zh_cn.tar.gz\n",
    "```\n",
    "where\n",
    "- `######` is a 6-digit unique identifier of the file on the OpenSubtitles dataset.\n",
    "- `Year` is the year the movie or episode was made.\n",
    "- `Id` is a 5 to 7 digit identifier (if it's 7-digit it's also an IMDb identifier).\n",
    "\n",
    "The subtitles are provided in different languages. We only analyze the `OpenSubtitles2018` folder and it's the only folder we detail.\n",
    "\n",
    "The decompressed XML files vary in size, ranging from 5KB to 9000KB sized files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML Files\n",
    "\n",
    "Each XML file is split into a `document` and `metadata` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtitles\n",
    "\n",
    "The `document` section contains all the subtitles and its general structure is the following:\n",
    "\n",
    "```\n",
    "├── s\n",
    "│   ├── time: Integer\n",
    "│   ├── w: String\n",
    "```\n",
    "\n",
    "An example snippet of an XML file:\n",
    "\n",
    "```xml\n",
    "  <s id=\"1\">\n",
    "    <time id=\"T1S\" value=\"00:00:51,819\" />\n",
    "    <w id=\"1.1\">Travis</w>\n",
    "    <w id=\"1.2\">.</w>\n",
    "    <time id=\"T1E\" value=\"00:00:53,352\" />\n",
    "  </s>\n",
    "```\n",
    "\n",
    "The subtitles in each XML file are stored by **blocks** denoted by `s` with a unique `id` attribute (integers in increasing order starting at 1).  \n",
    "\n",
    "Each block (`<s id=\"1\">` for instance) has a:  \n",
    "\n",
    "1. Set of timestamps (denoted by `time`) with\n",
    " - A timestamp `id` attribute that can take two different formats: `T#S` or `T#E`, where _S_ indicates _start_, _E_ indicates _end_ and _#_ is an increasing integer. \n",
    " - A `value` attribute which has the format `HH:mm:ss,fff`.\n",
    "\n",
    "2. Set of words (denoted by `w`) with\n",
    " - an `id` attribute that is simply an increasing number of decimal numbers of the format `X.Y` where X is the string id and Y is the word id within the corresponding string\n",
    " - a non-empty `value` attribute that contains a token: a word or a punctuation character. \n",
    "\n",
    "It sometimes also has an `alternative`, `initial` and `emphasis` attribute.  \n",
    "\n",
    " - The `initial` attribute generally corresponds to slang words or mispronounced words because of an accent such as _lyin'_ instead of _lying_.  \n",
    " - The `alternative` attribute is another way of displaying the subtitle for example _HOW_ instead of _how_.\n",
    " - The `emphasis` attribute is a boolean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "The `metadata` section has the following structure:\n",
    "\n",
    "```\n",
    "├── Conversion\n",
    "│   ├── corrected_words: Integer\n",
    "│   ├── sentences: Integer\n",
    "│   ├── tokens: Integer\n",
    "│   ├── encoding: String (always utf-8)\n",
    "│   ├── unknown_words: Integer\n",
    "│   ├── ignored_blocks: Integer\n",
    "│   ├── truecased_words: Integer\n",
    "├── Subtitle\n",
    "│   ├── language: String\n",
    "│   ├── date: String\n",
    "│   ├── duration: String\n",
    "│   ├── cds: String (presented as #/# where # is an int)\n",
    "│   ├── blocks: Integer\n",
    "│   ├── confidence: Double\n",
    "├── Source\n",
    "│   ├── genre: String[] (up to 3 genres)\n",
    "│   ├── year: Integer\n",
    "│   ├── duration: Integer (in minutes)\n",
    "│   ├── original: String\n",
    "│   ├── country: String\n",
    "```\n",
    "\n",
    "We note that some XML files may not have all the entries. \n",
    "We can use the metadata to obtain additional information about the movie or show's subtitles and compute certain statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "Going through the dataset we notice a few things:\n",
    "\n",
    "1. The dataset has meaningless folders. For example, the folder 1858/ is empty.\n",
    "2. Dataset contains XML files that are not related to movies or TV shows. For example, the folder 666/ contains Justin Bieber song subtitles.  \n",
    "3. Trailer of films can be present in the dataset. For example, the folder 2018/ we found for example Black Panther teaser trailer subtitles.\n",
    "4. Each movie might have more than 1 subtitle file.\n",
    "5. Some subtitle files contain text that is not related to the movie, like credits to the person who made the subtitles.\n",
    "6. The IDMDb folder name is not always a 7-digit number, meaning it is not always a valid IMDb identifer and we can't retrieve the IMDb info.\n",
    "7. Each block may have an arbitrary number (including 0) of timestamps associated to it.\n",
    "\n",
    "To solve points 1 and 2, we ignore all the folders which aren't inside the range of 1920-2018.\n",
    "\n",
    "To solve point 3, we drop trailers by looking at the `duration` field in the metadata section.\n",
    "\n",
    "To solve point 4, we simply take the first one.\n",
    "\n",
    "To solve point 6, we keep movies that have a correct IMDb identifier. Hence, all the files in folders that don't have a 7-digit folder name are dropped.\n",
    "\n",
    "To solve point 7, we decide not to associate a timestamp to each word for the moment.\n",
    " \n",
    "For the moment, we take a sample of the dataset from the cluster (see python script `extract_sample_2.py`) by collecting 1 or 2 movies for each year in the range 1920-2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing an analysis of the files and considering the statistics we want to obtain taking the size of our data into account, we decide to load the metadata and sentences directly into 1 dataframe where we manipulate it as before. We decide not to extract all words at first as it would induce into very heavy computations. We store the text in an array of sentences where each sentence is an array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: long (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- conversion: struct (nullable = true)\n",
      " |    |    |-- corrected_words: long (nullable = true)\n",
      " |    |    |-- encoding: string (nullable = true)\n",
      " |    |    |-- ignored_blocks: long (nullable = true)\n",
      " |    |    |-- sentences: long (nullable = true)\n",
      " |    |    |-- tokens: long (nullable = true)\n",
      " |    |    |-- truecased_words: long (nullable = true)\n",
      " |    |    |-- unknown_words: long (nullable = true)\n",
      " |    |-- source: struct (nullable = true)\n",
      " |    |    |-- duration: long (nullable = true)\n",
      " |    |    |-- genre: string (nullable = true)\n",
      " |    |    |-- year: long (nullable = true)\n",
      " |    |-- subtitle: struct (nullable = true)\n",
      " |    |    |-- blocks: long (nullable = true)\n",
      " |    |    |-- cds: string (nullable = true)\n",
      " |    |    |-- confidence: double (nullable = true)\n",
      " |    |    |-- date: string (nullable = true)\n",
      " |    |    |-- duration: string (nullable = true)\n",
      " |    |    |-- language: string (nullable = true)\n",
      " |-- s: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _emphasis: boolean (nullable = true)\n",
      " |    |    |-- _id: long (nullable = true)\n",
      " |    |    |-- time: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |    |    |-- _id: string (nullable = true)\n",
      " |    |    |    |    |-- _value: string (nullable = true)\n",
      " |    |    |-- w: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |    |    |-- _alternative: string (nullable = true)\n",
      " |    |    |    |    |-- _emphasis: boolean (nullable = true)\n",
      " |    |    |    |    |-- _id: double (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|    _id|                meta|                   s|\n",
      "+-------+--------------------+--------------------+\n",
      "|6887453|[[0, utf-8, 2, 96...|[[, 1, [[, T1S, 0...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imdb_id = '6464116'\n",
    "df_document_example = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "                                     .options(rowTag='document') \\\n",
    "                                     .load('sample_dataset/2017/6464116/6887453.xml.gz')\n",
    "df_document_example.printSchema()\n",
    "df_document_example.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid confusion, we will set some naming conventions. We will refer to certain attributes as follows:\n",
    "\n",
    "- The `s` array as **blocks**\n",
    "- An element of blocks, as a **block**.\n",
    "- The `w` array as **elements**\n",
    "- An element of elements, as **element**.\n",
    "- `_VALUE` as a **token**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that converts the `w` column of the document to an array of sentences, where each sentence is an array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentences_array(sentences):\n",
    "    \"\"\"Function to map the struct containing the words \n",
    "    to a list of words \"\"\"\n",
    "    s_list = []\n",
    "    if sentences is None:\n",
    "        return s_list\n",
    "    for words in sentences:\n",
    "        w_list = []\n",
    "        if words and \"w\" in words and words[\"w\"]:\n",
    "            for w in words[\"w\"]:\n",
    "                if '_VALUE' in w and w['_VALUE']:\n",
    "                    w_list.append(w['_VALUE'])\n",
    "                \n",
    "            s_list.append(w_list)\n",
    "\n",
    "    return s_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a couple of udf functions we will later use for the manipulation of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to spark function\n",
    "udf_sentences_array = udf(to_sentences_array, ArrayType(ArrayType(StringType())))\n",
    "# Convert array of words into a single string\n",
    "udf_sentence = udf(lambda x: ' '.join(x), StringType())\n",
    "# Function to split genres\n",
    "udf_split = udf(str.split, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below structures our data to the format we want to then process all the queries we need: We link the movie with the proper imdbID, we get all the sentences, change the subtitle duration to be in seconds (We assume for this that they all have the same format and after exploring the dataset we know the vast majority does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_cleaning(df_document, imdb_id):\n",
    "    # Create IMDb ID and sentences column\n",
    "    df_film_sentences = df_document.withColumn(\"tconst\", lit(\"tt\" + imdb_id))\\\n",
    "                                   .withColumn(\"sentences\", udf_sentences_array(\"s\"))\n",
    "    \n",
    "    # Select metadata and previously created columns\n",
    "    df_result = df_film_sentences.selectExpr(\"tconst\",\n",
    "                                             \"meta.conversion.sentences as num_sentences\",\n",
    "                                             \"meta.source.genre\", \n",
    "                                             \"meta.source.year\", \n",
    "                                             \"meta.subtitle.blocks\",\n",
    "                                             \"meta.subtitle.duration as subtitle_duration\",\n",
    "                                             \"meta.subtitle.language\",\n",
    "                                             \"sentences\")\n",
    "    # Split genre column and convert subtitle duration to seconds\n",
    "    df_result = df_result.withColumn(\"genres\", udf_split(\"genre\")) \\\n",
    "                         .withColumn(\"subtitle_mins\", \n",
    "                                     unix_timestamp(df_result.subtitle_duration, \"HH:mm:ss,SSS\") / 60)\n",
    "    # Discard redundant columns\n",
    "    return df_result.select(\"tconst\", \"num_sentences\", \"year\", \"blocks\", \"subtitle_mins\", \"genres\", \"sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have an example of the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = false)\n",
      " |-- num_sentences: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- blocks: long (nullable = true)\n",
      " |-- subtitle_mins: double (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- sentences: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n",
      "+---------+-------------+----+------+-------------+--------------------+--------------------+\n",
      "|   tconst|num_sentences|year|blocks|subtitle_mins|              genres|           sentences|\n",
      "+---------+-------------+----+------+-------------+--------------------+--------------------+\n",
      "|tt6464116|          967|2017|   888|         40.7|[Action,Crime,Drama]|[[[, shots, firin...|\n",
      "+---------+-------------+----+------+-------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_document_example = dataframe_cleaning(df_document_example, imdb_id)\n",
    "df_document_example.printSchema()\n",
    "df_document_example.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_maker(path):\n",
    "    \"\"\"Create dataframe based on the document\"\"\"\n",
    "    df_film = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "                             .options(rowTag='document')\\\n",
    "                             .load(path)\n",
    "    return df_film"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a dataframe based on the sample dataset. We will later expand it to cover a bigger quantity of films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"sample_dataset/\"\n",
    "# Create empty dataframe with same schema\n",
    "df_films = spark.createDataFrame([], df_document_example.schema)\n",
    "\n",
    "for year in os.listdir(path):\n",
    "    if not year.startswith('.'):\n",
    "        for imdb_id in os.listdir(path + year):\n",
    "            if not imdb_id.startswith('.'):\n",
    "                current_path = path + year + \"/\" + imdb_id\n",
    "                for file in os.listdir(current_path):\n",
    "                        df_document = dataframe_maker(current_path + '/' + file)\n",
    "                        df_films = df_films.union(dataframe_cleaning(df_document, imdb_id))\n",
    "\n",
    "#             df_m.show()\n",
    "#             print(current_path + \"/\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a proper dataframe which will help us generate useful statistics. This is the resulting format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+----+------+------------------+--------------------+--------------------+\n",
      "|   tconst|num_sentences|year|blocks|     subtitle_mins|              genres|           sentences|\n",
      "+---------+-------------+----+------+------------------+--------------------+--------------------+\n",
      "|tt1165285|          337|1924|   319|28.066666666666666|             [Short]|[[BACKWARD, CURRE...|\n",
      "|tt1452522|          208|1924|   181|53.333333333333336| [Drama,History,War]|[[The, Battle, of...|\n",
      "|tt1002599|           10|1927|     9|               3.5|   [Animation,Short]|[[FIINBECK, HAS, ...|\n",
      "|tt1320310|           49|1928|    47|              7.55|      [Comedy,Short]|[[YAJI, AND, KITA...|\n",
      "|tt1886619|           98|1928|    76|             54.15|             [Drama]|[[The, night, coa...|\n",
      "|tt1002784|          141|1934|   138|55.983333333333334|             [Drama]|[[Song, of, the, ...|\n",
      "|tt1002784|          138|1934|   138| 55.96666666666667|             [Drama]|[[Song, of, the, ...|\n",
      "|tt1703934|           64|1935|    69|              9.85|   [Animation,Short]|[[NARRATOR, :], [...|\n",
      "|tt1855316|          578|1936|   555| 83.66666666666667|               [War]|[[Prometheus], [P...|\n",
      "|tt2082346|          343|1936|   575| 47.96666666666667|             [Drama]|[[Film, Material,...|\n",
      "|tt1315053|          956|1939|   931|              64.9|             [Drama]|[[COLOR, PRINT, O...|\n",
      "|tt4040518|          924|2014|  1713|111.16666666666667|       [Documentary]|[[Previously, on,...|\n",
      "|tt4040518|          903|2014|  1699|109.21666666666667|       [Documentary]|[[In, the, late, ...|\n",
      "|tt1426332|         1123|1940|  1006|             90.15|             [Drama]|[[A, Shochiku, Pr...|\n",
      "|tt1426332|         1154|1940|  1032|             90.15|             [Drama]|[[A, Shochiku, Pr...|\n",
      "|tt1616538|          560|1940|   503| 97.18333333333334|[Biography,Drama,...|[[Subtitle, updat...|\n",
      "|tt1177923|         1059|1944|   849| 80.96666666666667|               [War]|[[Our, plane, fli...|\n",
      "|tt4040514|          807|2014|  1646|             105.5|       [Documentary]|[[Previously, on,...|\n",
      "|tt4040514|          791|2014|  1632|104.96666666666667|       [Documentary]|[[In, April, of, ...|\n",
      "|tt2285449|          124|1946|   222|12.483333333333333|      [Family,Short]|[[DEFENSE, AGAINS...|\n",
      "+---------+-------------+----+------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_films.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join our dataframe with the IMDb dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+----+------+------------------+--------------------+--------------------+-------------+--------+\n",
      "|   tconst|num_sentences|year|blocks|     subtitle_mins|              genres|           sentences|averageRating|numVotes|\n",
      "+---------+-------------+----+------+------------------+--------------------+--------------------+-------------+--------+\n",
      "|tt1165285|          337|1924|   319|28.066666666666666|             [Short]|[[BACKWARD, CURRE...|          6.4|      47|\n",
      "|tt1452522|          208|1924|   181|53.333333333333336| [Drama,History,War]|[[The, Battle, of...|          5.0|      11|\n",
      "|tt1002599|           10|1927|     9|               3.5|   [Animation,Short]|[[FIINBECK, HAS, ...|          4.4|       5|\n",
      "|tt1320310|           49|1928|    47|              7.55|      [Comedy,Short]|[[YAJI, AND, KITA...|          5.4|      22|\n",
      "|tt1886619|           98|1928|    76|             54.15|             [Drama]|[[The, night, coa...|          7.7|      21|\n",
      "|tt1002784|          141|1934|   138|55.983333333333334|             [Drama]|[[Song, of, the, ...|          6.5|      92|\n",
      "|tt1002784|          138|1934|   138| 55.96666666666667|             [Drama]|[[Song, of, the, ...|          6.5|      92|\n",
      "|tt1703934|           64|1935|    69|              9.85|   [Animation,Short]|[[NARRATOR, :], [...|          6.8|       5|\n",
      "|tt1855316|          578|1936|   555| 83.66666666666667|               [War]|[[Prometheus], [P...|          6.3|       9|\n",
      "|tt2082346|          343|1936|   575| 47.96666666666667|             [Drama]|[[Film, Material,...|          5.3|      87|\n",
      "|tt1315053|          956|1939|   931|              64.9|             [Drama]|[[COLOR, PRINT, O...|          7.3|      24|\n",
      "|tt4040518|          924|2014|  1713|111.16666666666667|       [Documentary]|[[Previously, on,...|          8.6|      94|\n",
      "|tt4040518|          903|2014|  1699|109.21666666666667|       [Documentary]|[[In, the, late, ...|          8.6|      94|\n",
      "|tt1426332|         1123|1940|  1006|             90.15|             [Drama]|[[A, Shochiku, Pr...|          7.0|      69|\n",
      "|tt1426332|         1154|1940|  1032|             90.15|             [Drama]|[[A, Shochiku, Pr...|          7.0|      69|\n",
      "|tt1616538|          560|1940|   503| 97.18333333333334|[Biography,Drama,...|[[Subtitle, updat...|          6.4|      44|\n",
      "|tt1177923|         1059|1944|   849| 80.96666666666667|               [War]|[[Our, plane, fli...|          6.4|      21|\n",
      "|tt4040514|          807|2014|  1646|             105.5|       [Documentary]|[[Previously, on,...|          8.4|      85|\n",
      "|tt4040514|          791|2014|  1632|104.96666666666667|       [Documentary]|[[In, April, of, ...|          8.4|      85|\n",
      "|tt2285449|          124|1946|   222|12.483333333333333|      [Family,Short]|[[DEFENSE, AGAINS...|          6.0|      33|\n",
      "+---------+-------------+----+------+------------------+--------------------+--------------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- tconst: string (nullable = false)\n",
      " |-- num_sentences: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- blocks: long (nullable = true)\n",
      " |-- subtitle_mins: double (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- sentences: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_films.join(df_ratings, [\"tconst\"]).show()\n",
    "df_films.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query to get number of sentences of best 50 films considering at least 20000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_ratings.filter(df_ratings.numVotes > 20000)\n",
    "df_50_best = df_films.join(df_filtered, [\"tconst\"])\\\n",
    "                     .orderBy(df_ratings.averageRating.desc()).select(\"num_sentences\", \n",
    "                                                                      \"averageRating\", \n",
    "                                                                      \"numVotes\").take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cest de la merde pour linstant vue la taille du dataset\n",
    "df_pd_example = pd.DataFrame(df_50_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>6.2</td>\n",
       "      <td>174384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1       2\n",
       "0  21  6.2  174384"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd_example\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
