{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Movie behind a Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.10:0.4.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.session.timeZone', 'UTC')\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were provided with a dataset of movie and tv show subtitles which contain for each video one or more xml files. The files supposedly have a corresponding IMDb identifier which can be linked to the IMDb datasets where we can extract useful information about a certain movie (rating, actors, director, etc) hence we decided to also use the IMDb dataset so we had more analytical tools in our disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSubtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Considering only the folder OpenSubtitles2018) The dataset presented consists of 31GB of xml files where we can find the subtitles in different languages of movies, tv shows and trailers. The data is separeted in different folders, first separating the subtitles by language, then by year and finally by identifier. Each Id is supposed to be its IMDb identifier but this needs to be checked. There are some year folders however that are not indicative, we can find folder 0. We can also notice that per film we can have multiple subtitle xml files. The decompressed xml files vary a great deal in size aswell, we can have 9000KB file and 5KB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each xml file has a document id and contains the following metadata splitted in 3 different categories: Conversion, Source, and Subtitle.\n",
    "\n",
    "Coversion contains:\n",
    "- Number of Sentences\n",
    "- Number of corrected words\n",
    "- Number of unknown words\n",
    "- Number of tokens\n",
    "- Encoding type\n",
    "\n",
    "Source contains:\n",
    "- Genre (Action, drama, horror, etc. Can have multiple)\n",
    "- Year\n",
    "\n",
    "Subtitle contains:\n",
    "- Language\n",
    "- Date (creation of file or release date of associated video?) -> XML file\n",
    "- Duration (of video associated)\n",
    "- Cds (can be 1/5, 2/3)\n",
    "- Blocks\n",
    "- Confidence\n",
    "\n",
    "We can use these metadata to find different statistics that might reveal interesting information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the actual subtitles in each xml file we can see that they are stored in sentences, each one having an unique id(integers in increasing order starting at 1). Each sentence has a set timestamps and a set of words. Every timestamp and word have also an id and a set of attributes. The timestamp id has two different formats. \n",
    "\n",
    "First for the timestamp id we have \"T#S\" or \"T#E\" where # is an increasing integer, \"S\" indicates start and \"E\" indicates end. The words inbetween a start and end of timestamp are shown on the screen during the time indicated by the time stamp. **This is a great indicator of fast dialog!**. Apart from the id, the timestamp also has a value attribute which has the format `` HH:mm:ss,fff``.\n",
    "\n",
    "For the words the id is simply an increasing number of decimal numbers \"X.Y\" where X is the string id and Y is the word id within the corresponding string. Each word element in the XML file has a non-empty value (the actual word, can be a mark) and it might have an alternative and initial value. The initial value corresponds to slang words generally, mispronounced words because of an accent such as lyin' instead of lying. The alternative is another way of displaying the subtitle for example HOW instead of how.\n",
    "\n",
    "There is another attribute we found for the strings and words which is not present in all the files and it is the emphasis attribute, which takes either true or false value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration\n",
    "\n",
    "After going through the dataset we found many things worth noting. First of all is that the dataset is not uniform, it has \"strange folders\" and contains xml files that are not related to movies or tv shows. We have for example the folder 666/ which contains Justin Bieber song subtitles, folder 1858/ which is empty and so on. To solve this we decided to ignore all the folders which weren't inside the range of 1920-2018. We also found that trailer of films are present in the dataset. In the folder 2018 we found for example Black Panther teaser trailer subtitles.\n",
    "\n",
    "Another thing worth mentioning is that a lot of different subtitles contain text that is not related to the movie, like credentials of the person who made the subtitles.\n",
    "\n",
    "We found that the code for the movies is not always reliable to get the actual movie name, hence we can't have 100% certainty that the id for the subtitles are associated with the correct film. We also see that each movie might have more than 1 subtitle file, we have to decide which one we should take. We can base this decision by taking one subtitle file at random or we could consider the confidence attribute in the metadata. To choose movies that can actually have a correct IMDb identifier we looked that the ID is composed of 7 integers, hence all the files in folders with more or less that 7 integers (after the year identifier) are very hard to associate with a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have at our disposal the IMDb ratings and basics dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseURL = \"https://datasets.imdbws.com/\"\n",
    "ratings_fn = \"title.ratings.tsv.gz\"\n",
    "basics_fn = \"title.basics.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>6.3</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>6.4</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  averageRating  numVotes\n",
       "0  tt0000001            5.8      1439\n",
       "1  tt0000002            6.3       172\n",
       "2  tt0000003            6.6      1040\n",
       "3  tt0000004            6.4       102\n",
       "4  tt0000005            6.2      1735"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv(baseURL + ratings_fn, sep='\\t', compression='gzip')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "   isAdult startYear endYear runtimeMinutes                    genres  \n",
       "0        0      1894      \\N              1         Documentary,Short  \n",
       "1        0      1892      \\N              5           Animation,Short  \n",
       "2        0      1892      \\N              4  Animation,Comedy,Romance  \n",
       "3        0      1892      \\N             \\N           Animation,Short  \n",
       "4        0      1893      \\N              1              Comedy,Short  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basics = pd.read_csv(baseURL + basics_fn, sep='\\t', compression='gzip')\n",
    "df_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: long (nullable = true)\n",
      " |-- time: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _id: string (nullable = true)\n",
      " |    |    |-- _value: string (nullable = true)\n",
      " |-- w: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _id: double (nullable = true)\n",
      "\n",
      "+---+--------------------+--------------------+\n",
      "|_id|                time|                   w|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|[[, T1S, 00:00:10...|[[\", 1.1], [ahmad...|\n",
      "|  2|[[, T2S, 00:00:56...|[[Well, 2.1], [,,...|\n",
      "|  3|[[, T3S, 00:00:58...|[[What, 3.1], [ki...|\n",
      "|  4|[[, T5S, 00:01:09...|[[Crazy, 4.1], [....|\n",
      "|  5|[[, T6S, 00:01:10...|[[Got, 5.1], [me,...|\n",
      "|  6|[[, T7S, 00:01:18...|[[Serious, 6.1], ...|\n",
      "|  7|[[, T7E, 00:01:23...|[[I, 7.1], [feel,...|\n",
      "|  8|[[, T8S, 00:01:25...|[[Alright, 8.1], ...|\n",
      "|  9|[[, T8E, 00:01:29...|[[See, 9.1], [ya,...|\n",
      "| 10|[[, T9S, 00:01:32...|[[Okay, 10.1], [,...|\n",
      "| 11|[[, T10S, 00:01:3...|[[It, 11.1], ['s,...|\n",
      "| 12|[[, T11S, 00:01:4...|[[Okay, 12.1], [,...|\n",
      "| 13|[[, T12S, 00:01:4...|[[Keep, 13.1], [g...|\n",
      "| 14|[[, T13S, 00:01:4...|[[I, 14.1], [thin...|\n",
      "| 15|[[, T14S, 00:01:5...|[[Go, 15.1], [str...|\n",
      "| 16|[[, T15S, 00:02:1...|[[I, 16.1], [just...|\n",
      "| 17|                null|[[I, 17.1], [don,...|\n",
      "| 18|[[, T15E, 00:02:1...|[[Just, 18.1], [k...|\n",
      "| 19|[[, T16S, 00:02:2...|[[Fuck, 19.1], [t...|\n",
      "| 20|[[, T17S, 00:02:2...|[[Not, 20.1], [to...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample_film = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "                                .options(rowTag='s') \\\n",
    "                                .load('data_subtitles/2017/5052448/6963336.xml.gz')\n",
    "df_sample_film.printSchema()\n",
    "df_sample_film.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_metadata = sqlContext.read.format('com.databricks.spark.xml')\\\n",
    "                                    .options(rowTag='meta') \\\n",
    "                                    .load('data_subtitles/2017/5052448/6963336.xml.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- conversion: struct (nullable = true)\n",
      " |    |-- corrected_words: long (nullable = true)\n",
      " |    |-- encoding: string (nullable = true)\n",
      " |    |-- ignored_blocks: long (nullable = true)\n",
      " |    |-- sentences: long (nullable = true)\n",
      " |    |-- tokens: long (nullable = true)\n",
      " |    |-- truecased_words: long (nullable = true)\n",
      " |    |-- unknown_words: long (nullable = true)\n",
      " |-- source: struct (nullable = true)\n",
      " |    |-- duration: long (nullable = true)\n",
      " |    |-- genre: string (nullable = true)\n",
      " |    |-- year: long (nullable = true)\n",
      " |-- subtitle: struct (nullable = true)\n",
      " |    |-- blocks: long (nullable = true)\n",
      " |    |-- cds: string (nullable = true)\n",
      " |    |-- confidence: double (nullable = true)\n",
      " |    |-- date: string (nullable = true)\n",
      " |    |-- duration: string (nullable = true)\n",
      " |    |-- language: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|          conversion|              source|            subtitle|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[0, utf-8, 0, 129...|[104, Horror,Myst...|[858, 1/1, 1.0, 2...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample_metadata.printSchema()\n",
    "df_sample_metadata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                   w|               ws|\n",
      "+--------------------+-----------------+\n",
      "|[[\", 1.1], [ahmad...|         [\", 1.1]|\n",
      "|[[\", 1.1], [ahmad...|     [ahmad, 1.2]|\n",
      "|[[\", 1.1], [ahmad...|    [torifi, 1.3]|\n",
      "|[[\", 1.1], [ahmad...|         [\", 1.4]|\n",
      "|[[\", 1.1], [ahmad...|  [subtitle, 1.5]|\n",
      "|[[Well, 2.1], [,,...|      [Well, 2.1]|\n",
      "|[[Well, 2.1], [,,...|         [,, 2.2]|\n",
      "|[[Well, 2.1], [,,...|       [the, 2.3]|\n",
      "|[[Well, 2.1], [,,...|     [thing, 2.4]|\n",
      "|[[Well, 2.1], [,,...|         [I, 2.5]|\n",
      "|[[Well, 2.1], [,,...|       ['ve, 2.6]|\n",
      "|[[Well, 2.1], [,,...|      [been, 2.7]|\n",
      "|[[Well, 2.1], [,,...|    [asking, 2.8]|\n",
      "|[[Well, 2.1], [,,...|    [myself, 2.9]|\n",
      "|[[Well, 2.1], [,,...|        [is, 2.1]|\n",
      "|[[Well, 2.1], [,,...|      [..., 2.11]|\n",
      "|[[What, 3.1], [ki...|      [What, 3.1]|\n",
      "|[[What, 3.1], [ki...|     [kinda, 3.2]|\n",
      "|[[What, 3.1], [ki...|      [sick, 3.3]|\n",
      "|[[What, 3.1], [ki...|[individual, 3.4]|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample_film = df_sample_film.select('w', explode(col(\"w\")).alias('ws'))\n",
    "df_sample_film.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentence(words):\n",
    "    w_list = []\n",
    "    for w in words:\n",
    "        w_list.append(w[0])\n",
    "    return w_list\n",
    "udf_word = udf(to_sentence, ArrayType(StringType()))\n",
    "udf_sentence = udf(lambda x: ' '.join([w[0] for w in x]), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+\n",
      "|                   w|               ws|            sentence|\n",
      "+--------------------+-----------------+--------------------+\n",
      "|[[\", 1.1], [ahmad...|         [\", 1.1]|[\", ahmad, torifi...|\n",
      "|[[\", 1.1], [ahmad...|     [ahmad, 1.2]|[\", ahmad, torifi...|\n",
      "|[[\", 1.1], [ahmad...|    [torifi, 1.3]|[\", ahmad, torifi...|\n",
      "|[[\", 1.1], [ahmad...|         [\", 1.4]|[\", ahmad, torifi...|\n",
      "|[[\", 1.1], [ahmad...|  [subtitle, 1.5]|[\", ahmad, torifi...|\n",
      "|[[Well, 2.1], [,,...|      [Well, 2.1]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|         [,, 2.2]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|       [the, 2.3]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|     [thing, 2.4]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|         [I, 2.5]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|       ['ve, 2.6]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|      [been, 2.7]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|    [asking, 2.8]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|    [myself, 2.9]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|        [is, 2.1]|[Well, ,, the, th...|\n",
      "|[[Well, 2.1], [,,...|      [..., 2.11]|[Well, ,, the, th...|\n",
      "|[[What, 3.1], [ki...|      [What, 3.1]|[What, kinda, sic...|\n",
      "|[[What, 3.1], [ki...|     [kinda, 3.2]|[What, kinda, sic...|\n",
      "|[[What, 3.1], [ki...|      [sick, 3.3]|[What, kinda, sic...|\n",
      "|[[What, 3.1], [ki...|[individual, 3.4]|[What, kinda, sic...|\n",
      "+--------------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample_film_sentence_list = df_sample_film.withColumn(\"sentence\", udf_word(\"w\"))\n",
    "df_sample_film_sentence_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+\n",
      "|                   w|               ws|            sentence|\n",
      "+--------------------+-----------------+--------------------+\n",
      "|[[\", 1.1], [ahmad...|         [\", 1.1]|\" ahmad torifi \" ...|\n",
      "|[[\", 1.1], [ahmad...|     [ahmad, 1.2]|\" ahmad torifi \" ...|\n",
      "|[[\", 1.1], [ahmad...|    [torifi, 1.3]|\" ahmad torifi \" ...|\n",
      "|[[\", 1.1], [ahmad...|         [\", 1.4]|\" ahmad torifi \" ...|\n",
      "|[[\", 1.1], [ahmad...|  [subtitle, 1.5]|\" ahmad torifi \" ...|\n",
      "|[[Well, 2.1], [,,...|      [Well, 2.1]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|         [,, 2.2]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|       [the, 2.3]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|     [thing, 2.4]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|         [I, 2.5]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|       ['ve, 2.6]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|      [been, 2.7]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|    [asking, 2.8]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|    [myself, 2.9]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|        [is, 2.1]|Well , the thing ...|\n",
      "|[[Well, 2.1], [,,...|      [..., 2.11]|Well , the thing ...|\n",
      "|[[What, 3.1], [ki...|      [What, 3.1]|What kinda sick i...|\n",
      "|[[What, 3.1], [ki...|     [kinda, 3.2]|What kinda sick i...|\n",
      "|[[What, 3.1], [ki...|      [sick, 3.3]|What kinda sick i...|\n",
      "|[[What, 3.1], [ki...|[individual, 3.4]|What kinda sick i...|\n",
      "+--------------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample_film_sentence_string = df_sample_film.withColumn(\"sentence\", udf_sentence(\"w\"))\n",
    "df_sample_film_sentence_string.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
